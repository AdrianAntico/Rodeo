% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FeatureEngineering_CharacterTypes.R
\name{CategoricalEncoding}
\alias{CategoricalEncoding}
\title{CategoricalEncoding}
\usage{
CategoricalEncoding(
  data = NULL,
  ML_Type = "classification",
  GroupVariables = NULL,
  TargetVariable = NULL,
  Method = NULL,
  SavePath = NULL,
  Scoring = FALSE,
  ImputeValueScoring = NULL,
  ReturnFactorLevelList = TRUE,
  SupplyFactorLevelList = NULL,
  KeepOriginalFactors = TRUE,
  Debug = FALSE
)
}
\arguments{
\item{data}{Source data.table}

\item{ML_Type}{Only use with Method "credibility'. Select from 'classification' or 'regression'.}

\item{GroupVariables}{Columns to encode}

\item{Method}{Method to utilize. Choose from 'credibility', 'target_encoding', 'woe', 'm_estimator', 'poly_encode', 'backward_difference', 'helmert'. Default is 'credibility' which is more specifically, Bulhmann Credibility}

\item{SavePath}{Path to save artifacts for recreating in scoring environments}

\item{Scoring}{Set to TRUE for scoring mode.}

\item{ImputeValueScoring}{If levels cannot be matched on scoring data you can supply a value to impute the NA's. Otherwise, leave NULL and manage them outside the function}

\item{ReturnFactorLevelList}{TRUE by default. Returns a list of the factor variable and transformations needed for regenerating them in a scoring environment. Alternatively, if you save them to file, they can be called for use in a scoring environment.}

\item{SupplyFactorLevelList}{The FactorCompenents list that gets returned. Supply this to recreate features in scoring environment}

\item{KeepOriginalFactors}{Defaults to TRUE. Set to FALSE to remove the original factor columns}

\item{Debug}{= FALSE}

\item{TargetVariabl}{Target column name}
}
\description{
Categorical encoding for factor and character columns
}
\examples{
\dontrun{
# Create fake data with 10 categorical
data <- AutoQuant::FakeDataGenerator(
  Correlation = 0.85,
  N = 1000000,
  ID = 2L,
  ZIP = 0,
  FactorCount = 10L,
  AddDate = FALSE,
  Classification = TRUE,
  MultiClass = FALSE)

# Take your pick
Meth <- c('m_estimator',
          'credibility',
          'woe',
          'target_encoding',
          'poly_encode',
          'backward_difference',
          'helmert')

# Pass to function
MethNum <- 1

# Mock test data with same factor levels
test <- data.table::copy(data)

# Run in Train Mode
data <- AutoQuant::CategoricalEncoding(
  data = data,
  ML_Type = "classification",
  GroupVariables = paste0("Factor_", 1:10),
  TargetVariable = "Adrian",
  Method = Meth[MethNum],
  SavePath = getwd(),
  Scoring = FALSE,
  ReturnFactorLevelList = FALSE,
  SupplyFactorLevelList = NULL,
  KeepOriginalFactors = FALSE,
  Debug = FALSE)

# View results
print(data)

# Run in Score Mode by pulling in the csv's
test <- AutoQuant::CategoricalEncoding(
  data = data,
  ML_Type = "classification",
  GroupVariables = paste0("Factor_", 1:10),
  TargetVariable = "Adrian",
  Method = Meth[MethNum],
  SavePath = getwd(),
  Scoring = TRUE,
  ImputeValueScoring = 222,
  ReturnFactorLevelList = FALSE,
  SupplyFactorLevelList = NULL,
  KeepOriginalFactors = FALSE,
  Debug = FALSE)
}

}
\seealso{
Other Feature Engineering: 
\code{\link{Apply_Asinh}()},
\code{\link{Apply_Asin}()},
\code{\link{Apply_BoxCox}()},
\code{\link{Apply_LogPlus1}()},
\code{\link{Apply_Logit}()},
\code{\link{Apply_Log}()},
\code{\link{Apply_Sqrt}()},
\code{\link{Apply_YeoJohnson}()},
\code{\link{AutoDataPartition}()},
\code{\link{AutoDiffLagN}()},
\code{\link{AutoInteraction}()},
\code{\link{AutoLagRollMode}()},
\code{\link{AutoLagRollStatsScoring}()},
\code{\link{AutoLagRollStats}()},
\code{\link{AutoTransformationCreate}()},
\code{\link{AutoTransformationScore}()},
\code{\link{AutoWord2VecModeler}()},
\code{\link{AutoWord2VecScoring}()},
\code{\link{CreateCalendarVariables}()},
\code{\link{CreateHolidayVariables}()},
\code{\link{DT_GDL_Feature_Engineering}()},
\code{\link{DummifyDT}()},
\code{\link{Estimate_BoxCox_Lambda}()},
\code{\link{Estimate_YeoJohnson_Lambda}()},
\code{\link{H2OAutoencoderScoring}()},
\code{\link{H2OAutoencoder}()},
\code{\link{Interact}()},
\code{\link{InvApply_Asinh}()},
\code{\link{InvApply_Asin}()},
\code{\link{InvApply_BoxCox}()},
\code{\link{InvApply_LogPlus1}()},
\code{\link{InvApply_Logit}()},
\code{\link{InvApply_Log}()},
\code{\link{InvApply_Sqrt}()},
\code{\link{InvApply_YeoJohnson}()},
\code{\link{ModelDataPrep}()},
\code{\link{Partial_DT_GDL_Feature_Engineering2}()},
\code{\link{Partial_DT_GDL_Feature_Engineering}()},
\code{\link{PercRankScoring}()},
\code{\link{PercRank}()},
\code{\link{StandardizeScoring}()},
\code{\link{Standardize}()},
\code{\link{Test_Asinh}()},
\code{\link{Test_Asin}()},
\code{\link{Test_BoxCox}()},
\code{\link{Test_Identity}()},
\code{\link{Test_LogPlus1}()},
\code{\link{Test_Logit}()},
\code{\link{Test_Log}()},
\code{\link{Test_Sqrt}()},
\code{\link{Test_YeoJohnson}()},
\code{\link{TimeSeriesFillRoll}()},
\code{\link{TimeSeriesFill}()}
}
\author{
Adrian Antico
}
\concept{Feature Engineering}
